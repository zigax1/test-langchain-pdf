{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edc2b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dad212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f5f0e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18453543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d23b82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "\n",
    "loader = OnlinePDFLoader('https://test-ziga-bucket12345.s3.amazonaws.com/ethical-data-science.pdf?AWSAccessKeyId=AKIA4HNXDNE6BASJXYJN&Signature=xZHcZrxwvamGDgRDkho7Yb3CIX0%3D&Expires=1684474819')\n",
    "document = loader.load()\n",
    "# from langchain.document_loaders import S3FileLoader\n",
    "# loader = S3FileLoader(\"test-ziga-bucket12345\", \"ethical-data-science.pdf\")\n",
    "# document = loader.load()\n",
    "# print(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c6956c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='A Guide for Ethical Data Science\\n\\nA collaboration between the Royal Statistical Society (RSS) and the Institute and Faculty of Actuaries (IFoA)\\n\\nAugust 2019\\n\\nContents\\n\\nIntroduction ............................................................................................................................................................... 2\\n\\nBackground\\n\\nRelevant themes\\n\\n1. Seek to enhance the value of data science for society ............................................................................ 5\\n\\n2. Avoid harm ............................................................................................................................................................ 6\\n\\n3. Apply and maintain professional competence ........................................................................................... 8\\n\\n4. Seek to preserve or increase trustworthiness ...........................................................................................10', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='5. Maintain accountability and oversight ..........................................................................................................11\\n\\nImplementation checklist .....................................................................................................................................12\\n\\nContact details ........................................................................................................................................................13\\n\\nDISCLAIMER\\n\\nThis guidance imposes no new obligations upon members. Rather the Institute and Faculty of Actuaries (‘the IFoA’) and the Royal Statistical Society (‘the RSS’) hopes that the guidance will be a useful tool for members. It does not constitute legal advice, nor does it necessarily provide a defence to allegations of misconduct. While care has been taken to ensure that it is accurate, up-to-date and useful, the IFoA and RSS will not accept any legal liability in relation to its contents.', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='1. Introduction\\n\\n1.1 This guide has been developed jointly by the Royal Statistical Society (RSS) Data Science Section and the Institute and Faculty of Actuaries (IFoA) for members working in the area of data science. It is intended to complement existing ethical and professional guidance and is aimed at addressing the ethical and professional challenges of working in a data science setting.\\n\\n1.2 While there is no single definition of data science, it can be broadly thought of as scientific, computational and\\n\\nanalytical methods used to process and extract information from data. It is synonymous with ‘big data’\\u200a1, machine learning (artificial intelligence), and data pipelines (automated systems that capture and process data). Data science brings together several fields including maths, statistics and computer science.\\n\\n1.3 The ethical significance of data science, and the implications for industries and the wider public, is constantly', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='evolving. As data science methods become more common within statistical and actuarial fields, there are both opportunities and challenges for individuals working in data science (‘practitioners’).\\n\\n1.4 For example, managing privacy, fairness and bias can be difficult and complex when using algorithmic methods. Additionally, public perceptions are still developing around many aspects of data science, including the use of artificial intelligence (AI) in systems and decision making, and ‘big data’ sources about people, such as social media and mobile phone data. The importance of keeping up with these challenging ethical issues led to the partnership between the RSS and the IFoA on the practical and ethical implications of data science.\\n\\n1.5 This partnership draws on both organisations’ commitment to ensuring high professional standards and\\n\\nupholding the public interest.\\n\\n2. Background', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='2.1 The RSS and IFoA developed this guide using a bottom-up approach, starting in 2018 with four workshops in\\n\\nwhich data science professionals were consulted on four key questions affecting the data science industry. Those questions were:\\n\\nWhat does a good data science workflow look like?\\n\\nHow should data science fit into the structure of an organisation?\\n\\nWhat do executives and managers need to know about data science?\\n\\nWhat is a data scientist’s responsibility to wider society?\\n\\n2.2 The key findings from the workshops included:\\n\\nbest practice for data science is dependent on the industry, organisational design, historical analytical\\n\\nworkflows and the availability of skills within data science teams', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='1 | ‘Big data’ is commonly defined as having one or more of the ‘four Vs’: Variety (includes unstructured formats eg images, videos, audio files, web pages, emails, and documents), Velocity (generated/updated at speed), Volume (cannot be held/analysed with traditional databases/statistical tools), Veracity (high levels of inconsistencies and uncertainty). It is also often used to refer to data about people’s behaviour, such as their digital footprint, social media use or mobile data.\\n\\n2\\n\\nthe data science professionals broadly agreed several high-level principles and practices around workflows, ethics, what executives need to know, and how to effectively place data science within the structure of an organisation\\n\\n2.3 While agreement for good practice was found across many aspects, some of the more complex issues will\\n\\nrequire further thought and input from the professions.', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='2.4 This guide considers five reoccurring ethical themes from existing ethical frameworks2 relating to data science\\n\\nand AI, with sources including government and industry, as well as bringing in discussion points arising from the joint workshops.\\n\\n2.5 This guidance is non-mandatory and does not impose any obligations upon RSS or IFoA members. Members must comply with any relevant and applicable professional body codes, standards of practice and legal or regulatory obligations, which take precedence.3\\n\\n2.6 The guide will be reviewed regularly. If members have any queries or feedback, please contact\\n\\ndataethics@actuaries.org.uk\\n\\n3. Relevant themes and principles within data ethics\\n\\n3.1 There are five relevant ethical themes associated with data science. Within each of these themes are examples\\n\\nof corresponding working practices which aim to help members consider data ethics. This is a condensed outline and is not intended to be a comprehensive list of ethical principles.', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='3.2 The five themes for consideration are:\\n\\n1. Seek to enhance the value of data science for society\\n\\nAs the impact that data science can have on society could be significant, an important ethical consideration is what the potential implications could be on society as whole. A common theme within ethical frameworks discussing data science and AI is for practitioners to attempt to seek outcomes within their work which support the improvement of public wellbeing. This could involve practitioners seeking to share the benefits of data science and balancing this with the wellbeing of potentially affected individuals.\\n\\n2. Avoid harm\\n\\nData science has the potential to cause harm and this ethical consideration therefore focuses on how\\n\\npractitioners can avoid this by working in a manner that respects the privacy, equality and autonomy of individuals and groups, and speaking up about potential harm or ethical violations.', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Practitioners may be subject to legal and regulatory obligations in relation to the privacy of individuals,\\n\\nrelevant to the jurisdiction in which they are working, as well as regulatory obligations to speak up about harm or violations of legal requirements.\\n\\nThis can also be applied to work relating to businesses, animals or the environment, with consideration of\\n\\ncommercial rights, animal welfare and the protection of environmental resources.\\n\\n2 | These are available in the additional references paper at www.rss.org.uk\\n\\n3 | Members of the Institute and Faculty of Actuaries carrying out technical actuarial work within the UK geographic scope are subject to the Financial Reporting\\n\\nCouncil Technical Actuarial Standards and must ensure that they comply with them.\\n\\n3\\n\\n3. Apply and maintain professional competence\\n\\nThis ethical principle expects data science practitioners to apply best practice and comply with all relevant', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='legal and regulatory requirements, as well as applicable professional body codes.\\n\\nProfessional competence involves fully understanding the sources of error and bias in data, using\\n\\n‘clean’ data (eg edited for missing, inconsistent or erroneous values), and supporting work with robust statistical and algorithmic methods that are appropriate to the question being asked. Practitioners can also thoroughly assess and balance the benefits of the work versus the risks posed by it, and keep models under regular review.\\n\\n4. Seek to preserve or increase trustworthiness\\n\\nThe public’s trust and confidence in the work of data scientists can be affected by the way ethical\\n\\nprinciples are applied. Practitioners can help to increase the trustworthiness of their work by considering ethical principles throughout all stages of a project.\\n\\nThis is another reoccurring theme that encourages practitioners to be transparent and honest when', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='communicating about the way data is used. Transparency can include fully explaining how algorithms are being used, if and why any decisions have been delegated, and being open about the risks and biases.\\n\\nEngaging widely with a diverse range of stakeholders and considering public perceptions both from the outset, and throughout projects, can help to build trustworthiness and ensure all potential biases are understood.\\n\\n5. Maintain accountability and oversight\\n\\nAnother key issue in data ethics around automation and AI is the question of how practitioners maintain\\n\\nhuman accountability and oversight within their work.', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Being accountable can include being mindful of how and when to delegate any decision making to systems, and having governance in place to ensure systems deliver the intended objectives. When deciding to delegate any decision making, it would be useful to fully understand and explain the potential implications of doing so, as the work could lead to introducing advanced AI systems which do not have adequate governance. Practitioners should note that delegating any decisions to these systems does not remove any of their individual responsibilities.\\n\\n4\\n\\n1. Seek to enhance the value of data science for society', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Data science has the potential to be both beneficial and detrimental to individuals and/or the wider public. To help minimise any adverse effects, members can seek to understand the potential impact of their work and consider any opportunities that may deliver benefits for the public. It is recognised that not all work will have a defined societal benefit, but members could strive to seek fairness or an overall increase to well being, within commercial applications.\\n\\n‘Public or societal good’ has many aspects and could include:\\n\\neconomic empowerment\\n\\nhealth and hunger\\n\\nemployment\\n\\neducation\\n\\nenvironment\\n\\ninformation certification and validation\\n\\ninfrastructure\\n\\npublic and social sector\\n\\nequality and inclusion\\n\\nsecurity and justice\\n\\nthe concept of fairness\\n\\ncyber risk to national security.\\n\\nPractice examples\\n\\n.\\n\\nBelow is a table of examples of how this principle could be put into practice:\\n\\nPractices\\n\\nWhat\\n\\nHow', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Considering the potential impact that models have on decisions (especially in relation to people)\\n\\nUnderstanding how the models will be used, what impact there may be and\\n\\nfor whom\\n\\nUnderstanding who the relevant stakeholders are\\n\\nUnderstanding the potential biases, errors, assumptions and risks inherent in\\n\\npredictive modelling\\n\\nInviting peer and bias review\\n\\nSeeking to act in the public interest\\n\\nChoosing or seeking work that is considered to have a benefit to the\\n\\npublic/society\\n\\nUnderstanding how the benefits may be distributed across society\\n\\nConsidering who or what could be affected by outcomes\\n\\nThinking about what could mitigate any risks for unfairness\\n\\nLeaders encouraging a culture which values social justice and fairness\\n\\n5\\n\\n2. Avoid harm', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Data science can involve using potentially sensitive data, such as an individual’s personal information, or have underlying sensitivity due to the volume of data and its ability to link with other sources. Additionally, newer sources of data, such as social media, have limited capacity for informed consent.\\n\\nExamples of potential harm could include:\\n\\nfinancial loss or disadvantage\\n\\ndamage to reputation, privacy or psychological wellbeing\\n\\nexclusion from benefits or services.\\n\\nThis applies to individuals, public bodies and private organisations. Therefore, as well as applying applicable legal and regulatory obligations, members are encouraged to think broadly about how data could cause harm, both in the context of its current purpose, and any future uses if the data is kept, linked or shared.\\n\\nPractice examples\\n\\nThe following practices contain examples of ways to minimise and manage harm in data science work:\\n\\nPractices\\n\\nWhat\\n\\nHow', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Using data that is ‘ethically sourced’, for example where data subjects have knowingly given their data and the perceptions of data subjects have been considered\\n\\nUnderstanding and asking questions about the origin of the data, such as how it\\n\\nwas collected\\n\\nInvestigating the attached consents and legal uses for the data\\n\\nConsidering the privacy, dignity and fair treatment of individuals when selecting\\n\\ndata\\n\\nLeaders being aware of and understanding the implications of using ‘big data’\\n\\nLinking in privacy and ethics into work, as well as legal and regulatory requirements\\n\\nFollowing good data handling practices, including data security, and\\n\\nconsidering ways to reduce the need for collecting, storing and utilising personally identifiable information\\n\\nConsidering the impact of deriving demographics or linking with other data\\n\\nBeing transparent and providing evidence of privacy considerations to the\\n\\npublic and/or regulators\\n\\n6\\n\\nWhat\\n\\nHow\\n\\nEmbedding ethical risk management into work', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Using ethical assessment checkpoints\\n\\nSeeking independent or domain-expert advice on assumptions and risks\\n\\nAppropriately monitoring and communicating ethical risks and potential biases\\n\\nto relevant stakeholders\\n\\nRegular ethical reviews of models/algorithms\\n\\nApplying organisational or industrial ethical policies\\n\\nLeaders putting clear ethical governance in place for data science work\\n\\nEducating the workforce to recognise the risks for harm and/or unfairness\\n\\nCommunicating to others what data science can and cannot do\\n\\nHelping non-technical individuals understand the ethical, professional and\\n\\ntechnical issues relevant to a project\\n\\nLeaders ensuring that their organisation as a whole understands the ethical\\n\\nprinciples and policies surrounding data science\\n\\nConsidering the impact on the environment and its resources\\n\\nFully understanding error, bias and risks associated with models applied to\\n\\nenvironmental problems', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Evaluating the energy-cost of storing and processing large volumes of data, and considering different options such as cloud computing, aggregating data and regularly reviewing the need for data\\n\\n7\\n\\n3. Applying and maintaining professional competence\\n\\nPractitioners can help minimise uncertainty and risk in their work by complying with best industry and professional practices and applying analytical rigour. This links closely with the other listed ethical considerations and can be challenging in the data science setting where the use of data is often complex.\\n\\nPractice examples\\n\\nThe following practices may help to maximise the benefits of data science and minimise potential harm.\\n\\nPractices\\n\\nWhat\\n\\nHow\\n\\nComplying with relevant professional and regulatory practices\\n\\nInvestigating what the relevant professional and legal/regulatory requirements\\n\\nare to the work in which you are involved\\n\\nEnsuring that the work complies with these requirements and justifying this to\\n\\nrelevant authorities', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Being aware of any evolving legal requirements and communicating these\\n\\nappropriately to relevant stakeholders\\n\\nEnsuring the business’s ethics policies, procedures and governance are applied to data science work\\n\\nProviding executive staff with enough information on the advantages and\\n\\nlimitations of the work to make decisions about the use of models\\n\\nUnderstanding and communicating to stakeholders and decision-makers the ethical risks of the project, such as bias, uncertainty, quality issues, individual/ commercial harm, methodology assumptions, disadvantages of chosen methods\\n\\nLeaders setting clear lines of responsibility\\n\\nEducating the workforce appropriately about relevant policies and procedures\\n\\nFollowing best practice for data analysis\\n\\nUsing appropriate statistical and algorithmic methods for the question being\\n\\naddressed\\n\\nLeaders taking the level of uncertainty in work into account when using data\\n\\nscience in any decision making\\n\\nMonitoring and maintaining models', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Having clear owners for models\\n\\nMonitoring the performance of models\\n\\nHaving regular reviews of models\\n\\nHaving an agreed action plan for updating or retiring models that are no longer\\n\\nfit for purpose\\n\\n8\\n\\nWhat\\n\\nHow\\n\\nValidating and improving work\\n\\nThoroughly quality-assuring data and analysis, including for bias, error,\\n\\nuncertainty\\n\\nEncouraging challenge from others involved in the project\\n\\nSharing appropriate code, diagnostics and results with colleagues/customers to\\n\\nensure they sufficiently understand the models\\n\\nPublishing results publicly where possible\\n\\nSeeking feedback from peers, academia or subject matter experts\\n\\n9\\n\\n4. Seek to preserve or increase trustworthiness', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Data science involves the analysis of varied sources of data and greater use of AI. As this is relatively new area, public perceptions are still evolving and developing. In order to build trust and understanding of their work, practitioners will need to work with the public and stakeholders. Trustworthiness can be built and maintained if organisations using data science engage regularly with stakeholders, including potential or actual critics, and have an open and honest dialogue about the use of data and AI. This engagement may also help to better understand potential sources of bias and risk.\\n\\nPractice examples\\n\\nBelow is a table describing how this could be put into practice.\\n\\nPractices\\n\\nWhat\\n\\nHow\\n\\nEngaging with appropriate ethical bodies\\n\\nLeaders in this area may wish to communicate with ethical bodies and the public\\n\\nabout how data is used and handled in relation to data science work\\n\\nAvoiding unnecessary complexity in methods to improve transparency', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Considering simpler models and documenting the performance of different\\n\\nmodels tested\\n\\nDisclosing the reasons for any improvements in accuracy if one model is\\n\\nfavoured over another\\n\\nBuilding trust through transparent communication with the public\\n\\nCommunicating the ways in which data is used and the benefits to customers/\\n\\nwider public\\n\\nTaking accountability for involvement in the work\\n\\nConsidering the views of the public and data subjects along with associated\\n\\nconsents and legal uses of data\\n\\nPublishing and sharing methods with relevant internal stakeholders, customers\\n\\nand the wider public, clearly referencing limitations, bias and uncertainty\\n\\nBeing honest and objective in communications\\n\\n10\\n\\n5. Maintain accountability and oversight', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='There are various emerging views on how to manage AI and whether it poses risks to society as well as opportunities. A common ethical consideration is how accountable individuals are when introducing AI and what level of oversight is put into place when delegating any decision making to machines.\\n\\nPractice examples\\n\\nBelow is a table describing how this could be put into practice.\\n\\nPractices\\n\\nWhat\\n\\nMaintaining human oversight of automated solutions\\n\\nHow\\n\\nImplementing model governance by deciding how to monitor the model over\\n\\ntime, such as setting review points and sign-off\\n\\nAgreeing where responsibility lies for models in production (approval, reviews,\\n\\nlonger\\n\\n\\n\\nterm quality assurance)\\n\\nAgreeing a review process\\n\\nClearly defining operating constraints\\n\\nAdding clear constraints within systems and corresponding documentation to\\n\\ncontrol and communicate what systems can and cannot do\\n\\nPublic involvement\\n\\nUsing public engagement and involvement to feed into projects, where\\n\\nappropriate', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Checking what public concerns may be\\n\\nGovernance and accountability structures\\n\\nHaving ethics oversight committees where appropriate\\n\\nHaving clear processes for accountability so that stakeholders have a clear route\\n\\nto any redress\\n\\nTo find further reference material and resources on how this is put into practice, please visit www.actuaries.org.uk and www.rss.org.uk.\\n\\n11\\n\\nImplementation checklist\\n\\nThis summary of the ethical practices highlights when they can be implemented within a project to help embed ethics into data science work.\\n\\nProject planning\\n\\nProfessional competence might include:\\n\\nTo embed ethics when defining, scoping and initiating projects, you can:\\n\\nComplete an ethics assessment including:\\n\\nIs it in the public interest, and how might value be\\n\\ndistributed fairly?\\n\\nCan data be ethically sourced?\\n\\nAre there risks (privacy, harm, fairness) for individuals,\\n\\ngroups, businesses, environment?', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Best practices, analytical rigour, quality assurance of methods, including peer review\\n\\nMinimising complexity in models and algorithms, validating thoroughly\\n\\nFully explaining outcomes and uncertainty when making recommendations\\n\\nEngage with the public/stakeholders to gather perceptions\\n\\nImplementation and delivery\\n\\nSeek early feedback from domain experts\\n\\nDefine the governance for the project, including data security and handling\\n\\nData management\\n\\nTo embed ethics when operationalising and deploying models and systems, you can:\\n\\nBe transparent about when, how and why decisions have been delegated\\n\\nShare methods, results/limitations and code with relevant parties; invite feedback\\n\\nTo embed ethics when acquiring, storing and preparing data for analysis, you can:\\n\\nProfessional competence might include:\\n\\nFully understand the consents and legal uses of the data\\n\\nHave data security measures in place, and ensure staff are trained in data handling', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Consider impacts of data processes to privacy, bias and error; including linking data sources, estimating demographic or other omitted information\\n\\nProfessional competence might include:\\n\\nThorough quality checks\\n\\nApplying best practices for data cleaning (errors, inconsistency, missing values)\\n\\nDetecting and mitigating sources of bias\\n\\nApplying best practice in anonymisation before sharing data or disseminating outputs\\n\\nAdequate quality assurance of systems\\n\\nRegular reviews of models, with risk assessments\\n\\nCommunication and oversight\\n\\nTo embed ethics in communications:\\n\\nCommunicate with stakeholders throughout projects and help any non-technical individuals understand the technical and ethical issues\\n\\nBe honest and objective when communicating about work\\n\\nAnalysis and development\\n\\nLeaders can:\\n\\nTo embed ethics when analysing data, building models and designing systems, you can:\\n\\nApply consents and permitted uses, professional and regulatory requirements', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='Monitor risks identified at planning, assess for additional risks (harm, bias, error, privacy)\\n\\nEnsure the organisation has and understands ethical principles and policies\\n\\nEngage with ethical bodies, privacy groups, stakeholder groups, the public\\n\\n12\\n\\nRoyal Statistical Society 12 Errol Street London · EC1Y 8LX Tel: +44 (0) 20 7638 8998\\n\\nwww.rss.org.uk\\n\\nBeijing 14F China World Office 1 · 1 Jianwai Avenue Beijing · China 100004 Tel: +86 (10) 6535 0248\\n\\nEdinburgh Level 2 · Exchange Crescent · 7 Conference Square Edinburgh · EH3 8RA Tel: +44 (0) 131 240 1300\\n\\nHong Kong 1803 Tower One · Lippo Centre · 89 Queensway Hong Kong Tel: +852 2147 9418\\n\\nLondon (registered office) 7th Floor · Holborn Gate · 326-330 High Holborn London · WC1V 7PP Tel: +44 (0) 20 7632 2100\\n\\nOxford 1st Floor · Park Central · 40/41 Park End Street Oxford · OX1 1JD Tel: +44 (0) 1865 268 200\\n\\nSingapore 163 Tras Street · #07-05 Lian Huat Building Singapore 079024 Tel: +65 6906 0889\\n\\nwww.actuaries.org.uk', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'}), Document(page_content='© 2019 Institute and Faculty of Actuaries and Royal Statistical Society', metadata={'source': '/var/folders/75/y8knzw213r30fxk0786gs2b40000gn/T/tmpqld999ex'})]\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(document)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db07449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "from chromadb.utils import embedding_functions\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "persist_directory = 'db'\n",
    "embedding = embedding_functions.OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'),model_name=\"text-embedding-ada-002\")\n",
    "embeddingsOpenAi = OpenAIEmbeddings()\n",
    "chroma_client = chromadb.Client(Settings(chroma_api_impl=\"rest\",chroma_server_host=\"localhost\",chroma_server_http_port=\"8000\"))\n",
    "chroma_Vectorstore = Chroma(collection_name=\"collection-10\", embedding_function=embeddingsOpenAi, client=chroma_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c237a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ac102ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAIEmbeddingFunction' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load db\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vectordb \u001b[39m=\u001b[39m Chroma(persist_directory\u001b[39m=\u001b[39;49mpersist_directory, embedding_function\u001b[39m=\u001b[39;49membedding)\n\u001b[1;32m      3\u001b[0m \u001b[39m#qa = VectorDBQA.from_chain_type(llm=OpenAI(openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", vectorstore=vectordb)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ChatConnect/ChatConnectPOC/myenv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:94\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persist_directory \u001b[39m=\u001b[39m persist_directory\n\u001b[1;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mget_or_create_collection(\n\u001b[1;32m     93\u001b[0m     name\u001b[39m=\u001b[39mcollection_name,\n\u001b[0;32m---> 94\u001b[0m     embedding_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m     metadata\u001b[39m=\u001b[39mcollection_metadata,\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAIEmbeddingFunction' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "# load db\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "#qa = VectorDBQA.from_chain_type(llm=OpenAI(openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", vectorstore=vectordb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc13c63",
   "metadata": {},
   "source": [
    "# Load model and run questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85868f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=os.environ.get('OPENAI_API_KEY'), streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True,  output_key='answer')\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, chroma_Vectorstore.as_retriever(similarity_search_with_score=True),\n",
    "                                                            return_source_documents=True,verbose=True, \n",
    "                                                            memory=memory)\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are aspects of data science?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory.chat_memory.add_user_message(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85664a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "#messages_to_dict(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What are aspects of data science?\n",
      "Assistant: The aspects of data science are:\n",
      "\n",
      "1. Statistics, Math, Linear Algebra\n",
      "2. Programming (Python)\n",
      "Follow Up Input: What are aspects of data science?\n",
      "Standalone question:\u001b[0m\n",
      "Can you list the aspects of data science?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "It can help us to know our customers better, it can help us to optimize our processes, it can help us to take better decisions. Because of data science, data has become strategic asset.\n",
      "\n",
      "Aspects in Data Science\n",
      "\n",
      "Step 1. Statistics, Math, Linear Algebra\n",
      "\n",
      "Step 2. Programming (Python)\n",
      "\n",
      "“Data Scientist is a person who is better at\n",
      "\n",
      "statistics than any programmer and better\n",
      "\n",
      "at programming than any statistician.”\n",
      "\n",
      "Josh Wills\n",
      "\n",
      "\n",
      "\n",
      "Head of Data Engineering at\n",
      "\n",
      "Slack\n",
      "\n",
      "Demo\n",
      "\n",
      "Lulus Tepat Waktu ga kalian? http://bit.ly/demodsunai\n",
      "\n",
      "http://13.229.82.68:1949/check?nim={nimnya} http://13.229.82.68:1949/check?nim=1581009\n",
      "\n",
      "Thanks\n",
      "\n",
      "Follow us @femaledailynetwork\n",
      "\n",
      "Get Female Daily apps also at:\n",
      "\n",
      "Understand the business\n",
      "\n",
      "Collect & explore the data\n",
      "\n",
      "Prepare & process the data\n",
      "\n",
      "Build & validate the models\n",
      "\n",
      "Deploy & monitor the performance\n",
      "\n",
      "WHAT DOES A GOOD DATA SCIENTIST LOOK LIKE?\n",
      "\n",
      "Inquistive – skeptical and curious\n",
      "\n",
      "Coding – is good at coding, hacking, and general programming\n",
      "\n",
      "Knowledgeable – knows machine learning, statistics, and probability\n",
      "\n",
      "Scientiﬁc Method – Creates hypotheses, tests them, and updates understanding\n",
      "\n",
      "Product Oriented – knows how to build data products and visualizations to make data understandable to mere mortals\n",
      "\n",
      "Domain Knowledge – understands the business and how to tell the relevant story from business data. Able to ﬁnd answers to known unknowns.\n",
      "\n",
      "Commonly in Data Science:\n",
      "\n",
      "Supervised Learning (Classiﬁcation & Regression)\n",
      "\n",
      "1. 2. Unsupervised Learning (Clustering & Anomaly Detection) 3. 4. Deep Learning\n",
      "\n",
      "Reinforcement Learning\n",
      "\n",
      "What Data Science do in Female Daily Network\n",
      "\n",
      "Recommendation Engine\n",
      "\n",
      "NER\n",
      "\n",
      "Typo Correction (Jaksel type)\n",
      "\n",
      "Data science is the field of study that combines domain expertise, programming skills, and knowledge of math and statistics to extract meaningful insights from data. Data science practitioners apply machine learning algorithms to numbers, text, images, video, audio, and more to produce artificial intelligence (AI) systems that perform tasks which ordinarily require human intelligence. In turn, these systems generate insights that analysts and business users translate into tangible business value. (Data Robot)\n",
      "\n",
      "So Data Science is?\n",
      "\n",
      "Data Science is apply Data with Science\n",
      "\n",
      "Bern Jonathan\n",
      "\n",
      "Who is Data Scientist?\n",
      "\n",
      "Simply: A man who does data science things.\n",
      "\n",
      "Expertly: Build a Social Impact!\n",
      "\n",
      "Data Science?\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "Data Team\n",
      "\n",
      "What Data Science do?\n",
      "\n",
      "A typical data science process looks like this, which can be modified for specific use case:\n",
      "\n",
      "Understand the business\n",
      "\n",
      "Collect & explore the data\n",
      "\n",
      "Prepare & process the data\n",
      "\n",
      "Build & validate the models\n",
      "\n",
      "Deploy & monitor the performance\n",
      "\n",
      "shirt a customer might like or what medicine a physician should consider prescribing based on a designed\n",
      "\n",
      "optimization function, such as optimizing for customer clicks or for minimizing readmission rates to the hospital.\n",
      "\n",
      "Depending on the engineering background of these data scientists, these work products are either deployed\n",
      "\n",
      "directly to the production system, or if they are prototypes they are handed off to software engineers to help\n",
      "\n",
      "implement, optimize and scale them.\n",
      "\n",
      "Nearly With\n",
      "\n",
      "Automation Modeling\n",
      "\n",
      "Artiﬁcial Intelligence\n",
      "\n",
      "ETL\n",
      "\n",
      "Data Engineering\n",
      "\n",
      "Software Engineering\n",
      "\n",
      "Architecture Optimization\n",
      "\n",
      "Why Data Science is Important?\n",
      "\n",
      "Every business has data but its business value depends on how much they know about the data they have.\n",
      "\n",
      "Data Science has gained importance in recent times because it can help businesses to increase business value of its available data which in turn can help them to take competitive advantage against their competitors.\n",
      "Human: Can you list the aspects of data science?\u001b[0m\n",
      "Yes, the aspects of data science are:\n",
      "\n",
      "1. Statistics, Math, Linear Algebra\n",
      "2. Programming (Python)\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = qa({\"question\": query})\n",
    "\n",
    "#result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "#chat_history = [(query, result[\"answer\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72ee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the aspects of data science are:\\n\\n1. Statistics, Math, Linear Algebra\\n2. Programming (Python)'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e8b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=\"Why don't scientists trust atoms? \\n\\nBecause they make up everything.\", generation_info=None)]], llm_output={'token_usage': <OpenAIObject at 0x7f8c3933d630> JSON: {\n",
       "  \"completion_tokens\": 14,\n",
       "  \"prompt_tokens\": 12,\n",
       "  \"total_tokens\": 26\n",
       "}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.generate([\"Tell me a joke\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4d321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x7f8c37e30d30>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.add_documents()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9d8dcd9",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_thread import DocumentThread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9013e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
      "Using embedded DuckDB with persistence: data will be stored in: threads/thread_0/db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# th.loadDocument(0, \"field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90c30c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Can u explain what is data veracity?\n",
      "Assistant: Data veracity refers to the accuracy and trustworthiness of data. It is one of the four dimensions of data quality, along with data accuracy, data completeness, and data consistency. Veracity is particularly important in the context of big data, where the volume, velocity, and variety of data can make it difficult to determine what is accurate and what is not. Ensuring data veracity involves implementing processes and controls to validate data, detect errors, and correct inaccuracies. It also involves ensuring that data is properly secured and protected from unauthorized access or tampering.\n",
      "Follow Up Input: Can u explain it like u are explaining to a child?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "as it brings structure to your thinking. Back of the envelope calculations are an existence proof of your approach. Without this kind of preparation, computers are power tools that can produce lots of bad answers really fast.  ›Does the answer make sense? Can you explain the answer? Computers, unlike children, do what they are told. Make sure you spoke to it clearly by validating that the instructions you provided are the ones you intended. Document your assumptions and make sure they have not introduced bias in your work. ›Is it a finding or a mistake?  Be skeptical of surprise findings. Experience says that it if seems wrong, it probably is wrong. Before you accept that conclusion, however, make sure you understand  and can clearly explain why  it is wrong.  ›Does the analysis address the original intent? Make sure that you are not aligning the answer with the expectations of the client. Always speak the truth, but remember that answers of “your baby is ugly” require more, not less,\n",
      "\n",
      "Reason and common sense are foundational to Data Science. Without these, data is simply a collection of bits. Context, inferences and models are created by humans and carry with them biases and assumptions. Blindly trusting your analyses is a dangerous thing that can lead to erroneous conclusions. When you approach an analytic challenge, you should always pause to ask yourself the following questions: ›What problem are we trying  to solve? Articulate the answer as a sentence, especially when communicating with the end-user. Make sure that it sounds like an answer. For example, “Given a fixed amount of human capital, deploying people with these priorities will generate the best return on their time.” ›Does the approach make sense? Write out your analytic plan. Embrace the discipline of writing, as it brings structure to your thinking. Back of the envelope calculations are an existence proof of your approach. Without this kind of preparation, computers are power tools that can produce\n",
      "\n",
      "T H E   F I ELD   G U I D E   to  D A T A   S C I E N C E\n",
      "\n",
      "The Importance of Reason\n",
      "\n",
      "Beware: in the world of Data Science, if it walks like a duck and quacks like a duck, it might just be a moose.\n",
      "\n",
      "Data Science supports and encourages shifting between deductive (hypothesis-based) and inductive (pattern-based) reasoning. Inductive reasoning and exploratory data analysis provide a means to form or refine hypotheses and discover new analytic paths. Models of reality no longer need to be static. They are constantly tested, updated and improved until better models are found.\n",
      "\n",
      "to ensure understanding.Russel, Stuart, and Peter Norvig. “Artiﬁcial Intelligence: A Modern Approach.” Prentice Hall, 2009 Print. Detailed Table of AnalyticsGetting you to the right starting point isn’t enough. We also provide a translator so you understand what you’ve been told.Identifying several analytic techniques that can be applied to your problem is useful, but their name alone will not be much help. The Detailed Table of Analytics translates the names into something more meaningful. Once you’ve identified a technique in the Guide to Analytic Selection, find the corresponding row in the table. There you will find a brief description of the techniques, tips we’ve learned and a few references we’ve found helpful. THE FIELD GUIDE to  DATA SCIENCE\n",
      "Human: How would you explain data veracity to a child?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': \"Data veracity is like making sure that the information you have is true and correct. Just like how you check your homework to make sure you got all the answers right, we check the data to make sure it's accurate and not wrong. It's important to have true and correct information so we can make good decisions and solve problems.\",\n",
       " 'source_documents': [{'page_content': 'as it brings structure to your thinking. Back of the envelope calculations are an existence proof of your approach. Without this kind of preparation, computers are power tools that can produce lots of bad answers really fast.  ›Does the answer make sense? Can you explain the answer? Computers, unlike children, do what they are told. Make sure you spoke to it clearly by validating that the instructions you provided are the ones you intended. Document your assumptions and make sure they have not introduced bias in your work. ›Is it a finding or a mistake?  Be skeptical of surprise findings. Experience says that it if seems wrong, it probably is wrong. Before you accept that conclusion, however, make sure you understand  and can clearly explain why  it is wrong.  ›Does the analysis address the original intent? Make sure that you are not aligning the answer with the expectations of the client. Always speak the truth, but remember that answers of “your baby is ugly” require more, not less,',\n",
       "   'metadata': {'source': 'field-guide-to-data-science.pdf'}},\n",
       "  {'page_content': 'Reason and common sense are foundational to Data Science. Without these, data is simply a collection of bits. Context, inferences and models are created by humans and carry with them biases and assumptions. Blindly trusting your analyses is a dangerous thing that can lead to erroneous conclusions. When you approach an analytic challenge, you should always pause to ask yourself the following questions: ›What problem are we trying  to solve? Articulate the answer as a sentence, especially when communicating with the end-user. Make sure that it sounds like an answer. For example, “Given a fixed amount of human capital, deploying people with these priorities will generate the best return on their time.” ›Does the approach make sense? Write out your analytic plan. Embrace the discipline of writing, as it brings structure to your thinking. Back of the envelope calculations are an existence proof of your approach. Without this kind of preparation, computers are power tools that can produce',\n",
       "   'metadata': {'source': 'field-guide-to-data-science.pdf'}},\n",
       "  {'page_content': 'T H E   F I ELD   G U I D E   to  D A T A   S C I E N C E\\n\\nThe Importance of Reason\\n\\nBeware: in the world of Data Science, if it walks like a duck and quacks like a duck, it might just be a moose.\\n\\nData Science supports and encourages shifting between deductive (hypothesis-based) and inductive (pattern-based) reasoning. Inductive reasoning and exploratory data analysis provide a means to form or refine hypotheses and discover new analytic paths. Models of reality no longer need to be static. They are constantly tested, updated and improved until better models are found.',\n",
       "   'metadata': {'source': 'field-guide-to-data-science.pdf'}},\n",
       "  {'page_content': 'to ensure understanding.Russel, Stuart, and Peter Norvig. “Artiﬁcial Intelligence: A Modern Approach.”\\xa0Prentice Hall, 2009 Print.\\xa0Detailed Table of AnalyticsGetting you to the right starting point isn’t enough. We also provide a translator so you understand what you’ve been told.Identifying several analytic techniques that can be applied to your problem is useful, but their name alone will not be much help. The Detailed Table of Analytics translates the names into something more meaningful. Once you’ve identified a technique in the Guide to Analytic Selection, find the corresponding row in the table. There you will find a brief description of the techniques, tips we’ve learned and a few references we’ve found helpful. THE FIELD GUIDE to  DATA SCIENCE',\n",
       "   'metadata': {'source': 'field-guide-to-data-science.pdf'}}]}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# th.askQuestion(0, \"Can u explain it like u are explaining to a child?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86503ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'What is motne carlo method?',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'Human'},\n",
       " {'content': \"The Monte Carlo method is a computational algorithm that uses random sampling to obtain numerical results. It is particularly useful for numerical integration, solutions of differential equations, computing Bayesian posteriors, and high dimensional multivariate sampling. The method is named after the Monte Carlo Casino in Monaco, where the uncle of one of the method's creators would borrow money to gamble, and then use statistical methods to determine the best way to bet.\",\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'AIMessage'},\n",
       " {'content': 'What is SKYLIFE?',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'Human'},\n",
       " {'content': 'SKYLIFE is a self-supporting aluminum shade structure with a roof consisting of adjustable blades. It is a shading structure designed to enhance the liveability of outdoor spaces. It is manufactured by KE, a company that specializes in shading structures, including arm awnings, cassette awnings, drop awnings, canopies, and shelters. SKYLIFE has a modular system, allowing for an infinite number of modules to be installed side by side. It also has the option for illumination with LED strips and closures with vertical drop-down screens, sliding glass doors, and draped curtains.',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'AIMessage'},\n",
       " {'content': 'What is data veracity?',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'Human'},\n",
       " {'content': \"I'm sorry, I don't have enough context to answer your question. Could you please provide me with more information or context?\",\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'AIMessage'},\n",
       " {'content': 'Can u explain what is data veracity in term of data science?',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'Human'},\n",
       " {'content': 'Data veracity refers to the overall quality and correctness of the data in the context of data science. It is an equally important yet often overlooked dimension of big data, alongside data volume, velocity, and variety. Assessing data truthfulness is often subjective, and you must rely on your experience and an understanding of the data origins and context. Domain expertise is particularly critical for the latter. Although data accuracy assessment may also be subjective, there are times when quantitative methods may be used.',\n",
       "  'additional_kwargs': {},\n",
       "  'example': False,\n",
       "  'type': 'AIMessage'}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# th.getHistory(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DocumentThread(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
      "Using embedded DuckDB with persistence: data will be stored in: threads/thread_1/db\n"
     ]
    }
   ],
   "source": [
    "dt.loadPDFFile(\"field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c045dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: threads/thread_1/db\n"
     ]
    }
   ],
   "source": [
    "dt.loadThread()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
